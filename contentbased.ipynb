{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![user-user](./wallpaper.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content Based Recommeder System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import typing\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://towardsdatascience.com/word2vec-from-scratch-with-numpy-8786ddd49e72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['muchachos', 'de', 'palermo', 'soho']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def tokenize(text: str) -> list:\n",
    "    \"\"\"\n",
    "    Obtains tokens with a least 1 alphabet.\n",
    "    \"\"\"\n",
    "    pattern = re.compile(r'[A-Za-z]+[\\w^\\']*|[\\w^\\']*[A-Za-z]+[\\w^\\']*')\n",
    "    return pattern.findall(text.lower())\n",
    "\n",
    "tokenize('Muchachos de Palermo Soho')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'muchachos': 0, 'palermo': 1, 'soho': 2, 'de': 3},\n",
       " {0: 'muchachos', 1: 'palermo', 2: 'soho', 3: 'de'})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_mapping(tokens: list) -> tuple:\n",
    "    \"\"\"\n",
    "    Indexes tokens and ids.\n",
    "    \"\"\"\n",
    "    word_to_id: dict = dict()\n",
    "    id_to_word: dict = dict()\n",
    "    for i, token in enumerate(set(tokens)):\n",
    "        word_to_id[token] = i\n",
    "        id_to_word[i] = token\n",
    "    return word_to_id, id_to_word\n",
    "\n",
    "get_mapping(['muchachos', 'de', 'palermo', 'soho'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 4, 4]]),\n",
       " array([[1, 2, 0, 2, 3, 0, 1, 3, 4, 1, 2, 4, 2, 3]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def vane(tokens: list, word_to_id: dict, window_size: int = 3) -> tuple:\n",
    "    N = len(tokens)\n",
    "    X, Y = [], []\n",
    "    for i in range(N):\n",
    "        nbr_inds = list(range(max(0, i - window_size), i)) + \\\n",
    "                   list(range(i + 1, min(N, i + window_size + 1)))\n",
    "        for j in nbr_inds:\n",
    "            X.append(word_to_id[tokens[i]])\n",
    "            Y.append(word_to_id[tokens[j]])\n",
    "    X = np.array(X)\n",
    "    X = np.expand_dims(X, axis=0)\n",
    "    Y = np.array(Y)\n",
    "    Y = np.expand_dims(Y, axis=0)\n",
    "    return X, Y\n",
    "\n",
    "vane(['Lorem', 'Ipsum', 'Dolor', 'Sit', 'Amet'], {'Lorem': 0, 'Ipsum': 1, 'Dolor': 2, 'Sit': 3, 'Amet': 4}, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = \"After the deduction of the costs of investing, \" \\\n",
    "      \"beating the stock market is a loser's game.\"\n",
    "tokens = tokenize(doc)\n",
    "word_to_id, id_to_word = mapping(tokens)\n",
    "X, Y = generate_training_data(tokens, word_to_id, 3)\n",
    "vocab_size = len(id_to_word)\n",
    "m = Y.shape[1]\n",
    "# turn Y into one hot encoding\n",
    "Y_one_hot = np.zeros((vocab_size, m))\n",
    "Y_one_hot[Y.flatten(), np.arange(m)] = 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
